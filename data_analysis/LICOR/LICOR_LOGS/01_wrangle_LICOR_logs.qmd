---
title: "LICOR Data Processing"
author: "Bryan Blue"
e-mail: 'bryanblue@arizona.edu'
date: "Last Generated: `r Sys.Date()`"

execute:
  echo: false
format: 
  html:
    code-fold: true
    fig-width: 8
    fig-height: 6
  pdf:
    fig-width: 7
    fig-height: 5
---

```{r setup, include=FALSE}
#| echo: false

# #| tags: [parameters]
# names = "test"

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(lubridate)
library(tidyr)
library(ggplot2)
library(here)

# start in the current project directory
# this ensures relative paths will work
# independent of the location the script
here::here()
# https://www.regextester.com/ for regex checking

# constants to data paths
DATARAW <- "data_raw"
DATACLEAN <- "data_clean"
DATAUSER <- "data_user"

```

*Always Restart R before running any script!*  

# 01_load_LICOR_logs  

__All files (read or written) are assumed to be in UTF-8 and not ASCII. The units row contains special characters that will not render unless this is true. If these values do not render correctly in your software, see if there is an option to use UTF-8 or convert them to values you are able to use.__   
Currently loads one text log from a LICOR data set. It reads each chunk of data that contains a line with "[Header]".  
All lines are skipped unless a remarks row is found. This continues until a line with "[Data]" is found.  
All data and remarks lines are read and assigned a group number to keep the related records together. This repeats until the end of file every time a "[Header]" line is found..  
The original group names, field names, and units are stored off in separate data frames from the first [Data] chunk.  
There are variable names that are not unique e.g. "time". Therefore the variable names are a concatenation of the group name and the variable name separated by an underscore. e.g. group "SysObs" and variable "time" are converted into a new name of "SysObs_time"    
All data files are written to a UTF-8, CSV type text file.  
__NOTE:__ Files that end in TXT should be imported into Excel using the import data option otherwise the UTF-8 units values do not import correctly.  
If a CSV data file is open directly in Excel, DO NOT "Convert large numbers into scientific notation", it may also ask that there are many 'E' values found, should they be treated as exponent values, do not do this either.

## REMARKS:
Remarks are found in both the [Header] section and [Data] section.  
There may be zero or more remarks present in either section.  
All should be read and concatenated into one comma delimited value for output as they are found.  
This means that the remarks field can change as data records are read and more remarks are found.  

Remarks start with time followed by a tab character.  
After the tab there are two possibilities  
1. "Stability Definition" (ignore)  
2. the actual remarks text (concatenate to remarks variable as found)  

__EXAMPLE LINES IN LOGFILE__  
12:44:30	Stability Definition:	A (GasEx): Slp<0.3 Per=15	gsw (GasEx): Slp<0.05 Per=15	F (FlrLS): Slp<5 Per=15  
12:44:44	tc-shade5


```{r functions}
#| echo: false

# given a fully qualified LI-COR data log file name
# process it into data frames of the groups, units, var names, data values
# add in a group number column representing a chunk of [Data], there may be many
# add in a remarks column that appends all remark lines as they are found in
# the [Header] section and within the [Data] section
load_data_chunks <- function(OutFile, OutFileName) {
  # print("function: load_data_chunks")
  # print(paste("OutFile:", OutFile))
  # print(paste("OutFileName:", OutFileName))
  
  con <- file(OutFile, "rt")
  # print("start")
  
  
  # init vars
  remarks <- "" # used to contain the list of remarks, if any
  i = 0 # used to specify which group of data is being read
  dataLines <- data.frame(matrix(ncol = 1, nrow = 0))
  colnames(dataLines) <- c("original")
  
  
  while (length(oneLine <- 
                readLines(con, n = 1, skipNul = TRUE, warn = FALSE)) > 0) {
    
    
    # get the remarks in header, add ones in [Data] block later
    if (str_detect(oneLine, regex("^[0-9]{2}:[0-9]{2}:[0-9]{2}\t")) &
        !str_detect(oneLine, regex("^[0-9]{2}:[0-9]{2}:[0-9]{2}\tStability Definition:\t"))) 
    {
      if (remarks == "") {
        remarks <- str_replace(oneLine, "\t", " ")
      } else {
        oneLine <- str_replace(oneLine, "\t", " ")
        remarks <- paste(remarks, oneLine, sep = ", ")
      }
    }
    
    
    # read all the records in the found [Data] block
    if (str_detect(oneLine, regex("\\[Data\\]"))) {
      # print("We found data start")
      
      # sequential numbering for each group of [Data] in the file
      i = i + 1
      groupNumber = paste("group",i, sep = "")
      
      # these three lines appear after [Data] in the file
      # add additional fields for filename, data group, remarks, and leaftype
      # NEW FIELD - add into all 3 paste groups
      dataGroups <- paste("Filenames", "Data", "Data", "Data",  "Data",
                          readLines(con, n = 1, skipNul = TRUE, warn = FALSE), sep = "\t")
      dataVars   <- paste("filename", "group", "remarks", "plant_id",  "leaftype",
                          readLines(con, n = 1, skipNul = TRUE, warn = FALSE), sep = "\t")
      dataUnits  <- paste("", "", "", "",  "",
                          readLines(con, n = 1, skipNul = TRUE, warn = FALSE), sep = "\t")
      
      # create an empty list to store all of the data records in the found block
      # read lines until it is not longer a data line
      while (length(dataLine <- readLines(con, n = 1, skipNul = TRUE, warn = FALSE)) > 0) {
        
        # remarks could be here too
        if (str_detect(dataLine, regex("^[0-9]{2}:[0-9]{2}:[0-9]{2}\t")) &
            !str_detect(dataLine, regex("^[0-9]{2}:[0-9]{2}:[0-9]{2}\tStability Definition:\t"))) 
        {
          if (remarks == "") {
            remarks <- str_replace(dataLine, "\t", " ")
          } else {
            dataLine <- str_replace(dataLine, "\t", " ")
            remarks <- paste(remarks, dataLine, sep = ", ")
          }
        }
        
        
        # lines starts with and integer record number and tab
        if (str_detect(dataLine, regex("^[0-9]?\t")) &
            !str_detect(dataLine, regex("^[0-9]{2}:[0-9]{2}:[0-9]{2}\t"))) {
          # NEW FIELD - add into this paste
          finalString <- paste(OutFileName, groupNumber, remarks, "", "", dataLine, sep = "\t")
          dataLines[nrow(dataLines) + 1,] = finalString
          # } else {
          #   break
        }
        
        # done reading data lines from the current block
        # reset remarks for next group of data       
        if (str_detect(dataLine, regex("\\[Header\\]"))) {
          remarks <- ""
          break
        }
      }
    }
    
  }
  # print("stop")
  close(con)
  
  return(list(dataGroups, dataUnits, dataVars, dataLines))
  
}
```
https://www.reneshbedre.com/blog/find-outliers.html

## Example IQR
x = c(10,4,6,8,9,8,7,6,12,14,11,9,8,4,5,10,14,12,15,7,10,14,24,28)

# get values of Q1, Q3, and IQR
summary(x)
Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
4.00    7.00    9.50   10.62   12.50   28.00 

# get IQR
IQR(x)
[1] 5.5

# get threshold values for outliers
Tmin = 7-(1.5*5.5) 
Tmax = 12.50+(1.5*5.5) 

# find outlier
x[which(x < Tmin | x > Tmax)]
[1] 24 28

# remove outlier
x[which(x > Tmin & x < Tmax)]
[1] 10  4  6  8  9  8  7  6 12 14 11  9  8  4  5 10 14 12 15  7 10 14


```{r remove_outliers}
#| echo: false
remove_outliers <- function(raw_data, FileName) {
  # file.path(
  # FileName = "2024-02-21-1317_logdata_lvl3"
  # raw_data = maindf[[4]]
  # daydata <- raw_data[raw_data$Filenames_filename==FileName,]$Data_group
  
  groups <- unique(raw_data$Data_group)
  
  
  for (gr in groups) {
    
    write_csv(filter(raw_data, (Filenames_filename == FileName & Data_group == gr & GasEx_A < 0)), 
              paste(DATAUSER, "outliers.csv"), 
              append = TRUE, 
              col_names = FALSE)
    raw_data <- filter(raw_data, !(Filenames_filename == FileName & Data_group == gr & GasEx_A <= 0))
    
    
    
    
    # tmp <- raw_data[raw_data$Filenames_filename == FileName & raw_data$Data_group == "group1",]  # retains NA  
    tmp <- filter(raw_data, Filenames_filename == FileName & Data_group == gr) # does not retain NA
    x <- tmp[,"GasEx_A"]
    # x = c(10,4,6,8,9,8,7,6,12,14,11,9,8,4,5,10,14,12,15,7,10,14,24,28)
    
    # get values of Q1, Q3, and IQR
    
    sm <- summary(x, digits = 8)
    
    # get IQR
    thresh <- IQR(x)
    
    Tmin = sm[2] - (1.5 * thresh) 
    Tmax = sm[5] + (1.5 * thresh) 
    
    # find outlier
    newlist <- x[which(x < Tmin | x > Tmax)]
    newlist
    
    # remove outlier
    rmout <- x[which(x > Tmin & x < Tmax)]
    rmout
    
    write_csv(filter(raw_data, (Filenames_filename == FileName & Data_group == gr & GasEx_A == newlist[1])), paste(DATAUSER, "outliers.csv"), 
              append = TRUE, 
              col_names = FALSE)
    
    raw_data <- filter(raw_data, !(Filenames_filename == FileName & Data_group == gr & GasEx_A == newlist[1])) # does not retain NA
    raw_data
  }
  
  return(raw_data)
}

```





```{r functions}
#| echo: false
# manipulate the data in valsdf using these varsdf column names
# special manipulations should go here
# normal rounding and formatting dates are common manipulations
fix_types <- function(typesdf) {
  # print("function: fix_types")
  # ggplot, other software has trouble with the large values in the data file
  # SIGDIF specifies the number of significant digits to retain, < 9 works
  SIGDIF = 8    # default number of digits for data readings
  # print(head(typesdf))
  
  # SysObs
  typesdf$SysObs_date <-     as.POSIXct(typesdf$SysObs_date, format = "%Y%m%d %H:%M:%S")
  typesdf$SysObs_obs <-      as.numeric(typesdf$SysObs_obs)
  typesdf$SysObs_time <-     round(as.numeric(typesdf$SysObs_time))
  typesdf$SysObs_elapsed <-  round(as.numeric(typesdf$SysObs_elapsed), digits = 0)
  
  #GasEx
  typesdf$GasEx_TIME <-  round(as.numeric(typesdf$GasEx_TIME))
  typesdf$GasEx_E <-     round(as.numeric(typesdf$GasEx_E), digits = SIGDIF)
  typesdf$GasEx_Emm <-   round(as.numeric(typesdf$GasEx_Emm), digits = SIGDIF)
  typesdf$GasEx_A <-     round(as.numeric(typesdf$GasEx_A), digits = SIGDIF)
  typesdf$GasEx_Ca <-    round(as.numeric(typesdf$GasEx_Ca), digits = SIGDIF)
  typesdf$GasEx_Ci <-    round(as.numeric(typesdf$GasEx_Ci), digits = SIGDIF)
  typesdf$GasEx_Pci <-   round(as.numeric(typesdf$GasEx_Pci), digits = SIGDIF)
  typesdf$GasEx_gsw <-   round(as.numeric(typesdf$GasEx_gsw), digits = SIGDIF)
  typesdf$GasEx_RHcham <-   round(as.numeric(typesdf$GasEx_RHcham), digits = SIGDIF)
  typesdf$GasEx_TleafCnd <- round(as.numeric(typesdf$GasEx_TleafCnd), digits = SIGDIF)
  typesdf$GasEx_VPcham <-   round(as.numeric(typesdf$GasEx_VPcham), digits = SIGDIF)
  typesdf$GasEx_VPDleaf <-  round(as.numeric(typesdf$GasEx_VPDleaf), digits = SIGDIF)
  
  #FLR
  
  typesdf$`FLR_Fv'/Fm'` <-    round(as.numeric(typesdf$`FLR_Fv'/Fm'`), digits = SIGDIF) 
  typesdf$`FLR_Fv/Fm` <-    round(as.numeric(typesdf$`FLR_Fv/Fm`), digits = SIGDIF) 
  # typesdf$FLR_Fv_prime_div_Fm_prime <- round(as.numeric(typesdf$FLR_Fv_prime_div_Fm_prime), digits = SIGDIF) # `FLR_Fv'/Fm'`
  typesdf$FLR_A_fs <-    round(as.numeric(typesdf$FLR_A_fs), digits = SIGDIF)
  typesdf$FLR_ETR	 <-    round(as.numeric(typesdf$FLR_ETR), digits = SIGDIF)
  typesdf$FLR_NPQ <-    round(as.numeric(typesdf$FLR_NPQ), digits = SIGDIF)
  
  
  # LeafQ
  typesdf$LeafQ_Qin <-    round(as.numeric(typesdf$LeafQ_Qin), digits = SIGDIF)
  
  # Meas
  typesdf$Meas_CO2_r<-    round(as.numeric(typesdf$Meas_CO2_r), digits = SIGDIF)
  typesdf$Meas_Pa	<-    round(as.numeric(typesdf$Meas_Pa), digits = SIGDIF)
  typesdf$Meas_Tair	<-    round(as.numeric(typesdf$Meas_Tair), digits = SIGDIF)
  typesdf$Meas_Tleaf<-    round(as.numeric(typesdf$Meas_Tleaf), digits = SIGDIF)
  
  return(typesdf) 
}


```



```{r select_data}
#| echo: true

select_data <- function(groupsdf, varsdf) {
  # print("function: select_data")
  # variable names are not unique, prepend the group to fix it
  new_field_list <- paste(groupsdf[1,], varsdf[1,], sep = "_")
  new_field_list <- str_replace_all(new_field_list, " ", "_")
  
  colnames(valuesdf) <- new_field_list
  
  # set the proper variable types
  # LI-COR data has values that are not consistent in number of sig digits
  #        inconsistent such as seconds appear as partial and full seconds in the same column
  valuesdf <- fix_types(valuesdf)
  
  # variable names are not unique, add suffix of the group to fix it
  new_select_field_list <- paste(select_field_list[1,], select_field_list[2,], sep = "_")
  colnames(unitsdf) <- new_field_list
  
  # create a set of data that the user specified in select_field_list
  final_data <- valuesdf %>% select(any_of(new_select_field_list))
  
  return(new_select_field_list)
}

```

__Write Data Files__
```{r write_files}
#| echo: false
#| 
write_files <- function(LogFileName, groupsdf, varsdf, unitsdf, valuesdf, final_data) {
  # print("function: write_files")
  # write out a text file that Excel can read
  # this file keep LICOR units in UTF-8 with special characters
  CleanDataFile <- paste("cleaned_UTF-8", LogFileName, sep = '_')
  CleanDataFile <- paste(CleanDataFile, "csv", sep = '.')
  CleanOutput <- here(DATACLEAN, CleanDataFile)
  
  write_csv(groupsdf, CleanOutput, append = FALSE, col_names = FALSE)
  write_csv(varsdf, CleanOutput, append = TRUE, col_names = FALSE)
  write_csv(unitsdf, CleanOutput, append = TRUE, col_names = FALSE)
  write_csv(valuesdf, CleanOutput, append = TRUE, col_names = FALSE)
  
  SelectedDataFile <- paste("selected", LogFileName, sep = '_')
  SelectedDataFile <- paste(SelectedDataFile, "csv", sep = '.')
  SelectedOutput <- here(DATACLEAN, SelectedDataFile)
  
  write_csv(final_data, SelectedOutput, append = FALSE, col_names = TRUE)
}

```

```{r add_user_variables}
#| echo: false
#| 
build_select_fieldlist <- function(groupsdf, varsdf) {
  # select the names for the columns of interest
  # UTF-8 CSV text file to keep units in proper form
  # only the variable names will appear in the selected output file
  # select_logdata_fields.csv must exist in the DATAUSER directory
  # three lines are required, one for the group, variable, and units
  # as they appear in the LICOR logs
  # print("function: build_select_fieldlist()")
  
  SelectDataFile <- "select_logdata_fields.csv"
  SelectInput <- here(DATAUSER, "input", SelectDataFile)
  select_field_list <- read_csv(SelectInput, 
                                col_names = FALSE, 
                                n_max = 2,
                                show_col_types = FALSE) 
  
  # Append new user defined columns to the front of data
  # row #1 = group name, row #2 = variable name
  sysdf <- data.frame(matrix(ncol = 5, nrow = 2))
  # the groups to add
  sysdf[1,1] <- groupsdf[1]
  sysdf[1,2] <- groupsdf[2]
  sysdf[1,3] <- groupsdf[3]
  sysdf[1,4] <- groupsdf[4]
  sysdf[1,5] <- groupsdf[5]
  
  # the variable names to add
  sysdf[2,1] <- varsdf[1]
  sysdf[2,2] <- varsdf[2]
  sysdf[2,3] <- varsdf[3]
  sysdf[2,4] <- varsdf[4]
  sysdf[2,5] <- varsdf[5]
  # select_field_list <- data.frame(sysdf, select_field_list)
  select_field_list <- cbind(sysdf, select_field_list)
  
  return(select_field_list)
}
```

__Processing Data from data_raw folder__  
```{r main}
#| echo: false
#| 
main <- function(LogFileName) {
  # print("function: main()")
  
  
  # LogFileName <- FileName # TODO !!!!!! testing with one file only !!!!!!
  # LogFileName <- FileList[1] # TODO !!!!!! testing with one file only !!!!!!
  # LogFileName <- "2023-11-15-1148_logdata"
  
  LogFullFileName <- here(DATARAW, LogFileName)
  
  output <- load_data_chunks(LogFullFileName, LogFileName)
  # print(paste("output: ", head(output[[4]][,1])))
  
  
  
  # output contains tabular data broken into the group, units, var names, and values
  # break them into their own tables for further use
  groupsdf <- data.frame(do.call('rbind',strsplit(as.character(output[[1]]),'\t',fixed=TRUE)))
  unitsdf <- data.frame(do.call('rbind',strsplit(as.character(output[[2]]),'\t',fixed=TRUE)))
  varsdf <- data.frame(do.call('rbind',strsplit(as.character(output[[3]]),'\t',fixed=TRUE)))
  valuesdf <- data.frame(do.call('rbind',strsplit(as.character(output[[4]][,1]),'\t',fixed=TRUE)))
  # print(paste("varsdf: ",varsdf))
  
  # LICOR variable names are not unique, add the group as a suffix to fix it
  full_field_list <- paste(groupsdf[1,], varsdf[1,], sep = "_")
  
  
  # LICOR variable names may contain spaces and other UTF-8 special characters
  # replace them with appropriate values for raw data handling
  full_field_list <- str_replace_all(full_field_list, " ", "_")
  # full_field_list <- str_replace_all(full_field_list, "/", "_div_")
  # full_field_list <- str_replace_all(full_field_list, "'", "_prime_")
  
  # df that need to have column names set to cleaned up field lists
  colnames(valuesdf) <- full_field_list
  colnames(unitsdf) <- full_field_list
  
  # set the proper variable types
  # LICOR data has values that are not consistent in number of sig digits
  # inconsistent such as seconds appear as partial and full seconds in the same column
  # convert all fields that can be converted to the correct type based on the data
  # TODO is type.convert() the best answer for global type updates?
  ############################
  # valuesdf <- type.convert(valuesdf, as.is = TRUE, numerals = "allow.loss") 
  # override of any types that may not convert as expected
  valuesdf <- fix_types(valuesdf)
  
  
  # TODO this function needs implemented ----------------------------
  # valuesdf <- remove_outliers(valuesdf, LogFileName)
  # NOT WORKING, TOO MANY ARE FLAGGED
  
  
  # create select list of groups and variables of interest
  select_field_list <- build_select_fieldlist(groupsdf, varsdf)
  # LICOR variable names are not unique, add the group as a suffix to fix it
  select_field_list <- paste(select_field_list[1,], select_field_list[2,], sep = "_")
  # LICOR variable names may contain spaces, replace with hyphens
  select_field_list <- str_replace_all(select_field_list, " ", "_")
  
  
  # create a set of data that the user specified in select_field_list
  final_data <- valuesdf %>% select(any_of(select_field_list))
  
  # write data
  write_files(LogFileName, groupsdf, varsdf, unitsdf, valuesdf, final_data)
  
  return(list(groupsdf, varsdf, unitsdf, valuesdf, final_data))
}
```

## NOTE: the remarks in the data files may not be 100% correct.  
Changes have been made in the leaf_identification.csv file as needed.

## NOTE LICOR logs default to start with the date "YYYY-MM-DD"
This ensures only these files are read. If files are not named in this convention, this will not work.  

2024-03-13-1130_logdata_lvl2 This day had the initial LI-COR environment  configured incorrectly. 
Log Descriptions were not set correctly and manually set. e.g. Reference and Treatment switched.  

```{r process_files}
#| echo: false

# NOTE LICOR logs default to start with the date "YYYY-MM-DD"
# this ensures only these files are read
# if files are not saved this way, it will not work
FileList <- list.files(DATARAW, pattern = "^[0-9]{4}-[0-9]{2}-[0-9]{2}")

for (FileName in FileList) {
  print(FileName)
  maindf <- main(FileName)
  
  # maindf contains the final results if anything is needed
  # groupsdf, varsdf, unitsdf, valuesdf, final_data
  # 1 - groupsdf
  # 2 - units
  # 3 - varsdf
  # 4 - valuesdf
  # 5 - final_data (selected data df)
}


```

