---
title: "LICOR Statistical Exploration"
author: "Bryan Blue"
e-mail: 'bryanblue@arizona.edu'
date: "Last Generated: `r Sys.Date()`"
execute:
  echo: false
format: 
  html:
    code-fold: true
    fig-width: 8
    fig-height: 6
  pdf:
    fig-width: 7
    fig-height: 4
    echo: false
---

```{r setup, include=FALSE}
#| echo: false
knitr::opts_chunk$set(echo = FALSE)
require(tidyverse)
library(dplyr)
library(lubridate)
require(tidyr)
library(ggplot2)
library(here)
library(patchwork)

# start in the current project directory
# this ensures relative paths will work
# independent of the location the script
here::here()
# https://www.regextester.com/ for regex checking

# constants to data paths
DATARAW <- "data_raw" 
DATACLEAN <- "data_clean"
DATAUSER <- "data_user"
ELEVATION <- 2 # elevation of the experiment, numeric value or 2 or 3
VARNAME <- "GasEx_A" # this the column name in finaldata where the group and variable are combined

# NOTE to self: Look into these for help with graph layout\
# patchwork TODO !!!!\
# wrap plot, axis collect

```

# Report for elevation: `r ELEVATION` on `r VARNAME`
This is an exploration of data normality and variance in the Treatment and Control data from this experiemnt.  Much of it is for exploration and would not be needed in any final report.  

# Load Final Data  
A `final_raw_data.csv` file is used for final analysis. This is a combination of all Treatment, Control, and Reference data for all elevations that was combined from the LICOR text logs in previous steps.

Data is read from a CSV file and `type.convert()` is used to guess the data types.\
Data types that are not correct are manually set to their appropriate values.\
Data is scrubbed for `r VARNAME` > 0. Values <= 0 are considered invalid values.\
Data is limited to `SysObs_time` \> 1668543540 seconds, the start of the experiment.

```{r functions}
#| echo: false
#| warning: false

read_final_data <- function(filename) {
  
  # finaldata <- read_csv(here(DATAUSER,"final_raw_data.csv"), 
  finaldata <- read_csv(filename, 
                        col_names = TRUE, 
                        show_col_types = FALSE) 

# try to auto convert all data types, not all work
finaldata <- type.convert(finaldata, as.is = TRUE)
# convert values that were not correctly auto converted
# finaldata$Data_leaftype <- as.factor(finaldata$Data_leaftype)
finaldata$Filenames_filename <- as.factor(finaldata$Filenames_filename)
finaldata$Data_plant_id <- as.factor(finaldata$Data_plant_id)
# finaldata$SysObs_date <-  as.POSIXct(finaldata$SysObs_date, format = "%Y%m%d %H:%M:%S")
# This needs converted into a true date type for graphing
finaldata$SysObs_date <-as.Date(finaldata$SysObs_date)
# error if <= 0 and arbitrary >= 7
# TODO this needs to be in the original cleaning code
    finaldata <- finaldata %>% filter(VARNAME > 0)

# The clock was off at one point, this needs corrected or ignore the values
# TODO this needs to bin the original cleanind code
finaldata <- finaldata %>%
  filter(Data_plant_id == ELEVATION & SysObs_time > 1668543540) %>% arrange(SysObs_date)
# finaldata <- finaldata %>% filter(!Filenames_filename == "2023-11-22-1138_logdata")

return(finaldata)

}

# standard plot of Treatment, Control, and Reference data
# plot_data is the df to plot 
# plantid is the elevation of interest values in the df
# sysobs is the numeric variable of interest from the LICOR log
mean_plant_data <- function(plot_data, plantid, sysobs) {
  plotdf <- plot_data %>% filter(Data_plant_id == plantid) %>%
    filter(Data_leaftype == "Treatment" | 
             Data_leaftype == "Control" | 
             Data_leaftype == "Reference") %>%
    arrange(SysObs_date)
  
  plotdf <- plotdf %>%
  group_by(Filenames_filename, Data_leaftype, SysObs_date) %>%
  summarise_at((sysobs), list(gm = mean))

  return(plotdf)
}

# basic plot of means
# plot_data is a df containing the data generated from mean_plant_data
# this df is assumed to have a column "gm" that contains the mean values
plot_means <- function(plot_data, title="", xlabel="", ylabel=""){
  plot1 <- ggplot() +
    geom_point(data=plot_data, 
              aes(x = SysObs_date, y = gm, color = Data_leaftype)) +
    # geom_line(data=plot_data, 
              # aes(x = SysObs_date, y = gm, color = Data_leaftype)) +
    ggtitle(title) +
    xlab(xlabel) +
    ylab(ylabel) +
    # scale_y_continuous(limits=c(0.0, 6.0))   +
    #     date_breaks = "10 sec",  expand = expansion(0)) +
    geom_smooth(method=lm, se=FALSE, col='red', size=2) +
    theme(axis.text.x=element_text(angle=60, hjust=1))
  
  return(plot1)
}

# a simple normal plat
# a df plotdata has a given leaftype graphed against a given variable
# leaftype is Treatment, Control, or Reference
normal_plot <- function(plotdata, leaftype, dfvariable, title) {
  nplot <- ggplot(plotdata[plotdata$Data_leaftype==leaftype,], aes(x = get(dfvariable))) +
    stat_function(
      fun = dnorm,
      args = with(plotdata, c(mean = mean(get(dfvariable)), sd = sd(get(dfvariable))))
    ) +
    scale_x_continuous(title)
  return(nplot)
}
```

## OUTLIERS
An observation is an outlier if it is 1.5 times the interquartile range greater than the third quartile (Q3) or 1.5 times the interquartile range less than the first quartile (Q1).

The interquartile range of the value of interest is calculated using the `IQR()` function.

A new df is created with the Outliers removed. This is used to calculate a df of the mean values for the variable of interest.

```{r data_wrangle}
#| echo: FALSE
#| error: TRUE
#| warning: FALSE
 
# the final, combined, and scrubbed data from all LICOR text logs
finaldata <- read_final_data(here(DATAUSER,"final_raw_data.csv"))

# OUTLIERS
# Define an observation to be an outlier if it is 1.5 times the 
# interquartile range greater than the third quartile (Q3) or 1.5 times the 
# interquartile range less than the first quartile (Q1).

# find Q1, Q3, and interquartile range for values in points column
finalTreat <- subset(finaldata, Data_leaftype == "Treatment")
Q1 <- quantile(finalTreat[[VARNAME]], .25)
Q3 <- quantile(finalTreat[[VARNAME]], .75)
IQR <- IQR(finalTreat[[VARNAME]])
# subset data where points value is outside 1.5*IQR of Q1 and Q3
outliersTreat <- subset(finalTreat, finalTreat[[VARNAME]]<(Q1 - 1.5*IQR) | finalTreat[[VARNAME]]>(Q3 + 1.5*IQR))
newTreat <-      subset(finalTreat, !(finalTreat[[VARNAME]]<(Q1 - 1.5*IQR) | finalTreat[[VARNAME]]>(Q3 + 1.5*IQR)))
# outliersTreat

finalCont <- subset(finaldata, Data_leaftype == "Control")
Q1 <- quantile(finalCont[[VARNAME]], .25)
Q3 <- quantile(finalCont[[VARNAME]], .75)
IQR <- IQR(finalCont[[VARNAME]])
# subset data where points value is outside 1.5*IQR of Q1 and Q3
outliersCont <- subset(finalCont, finalCont[[VARNAME]]<(Q1 - 1.5*IQR) | finalCont[[VARNAME]]>(Q3 + 1.5*IQR))
newCont <- subset(finalCont, !(finalCont[[VARNAME]]<(Q1 - 1.5*IQR) | finalCont[[VARNAME]]>(Q3 + 1.5*IQR)))
# outliersCont

finalRef <- subset(finaldata, Data_leaftype == "Reference")
Q1 <- quantile(finalRef[[VARNAME]], .25)
Q3 <- quantile(finalRef[[VARNAME]], .75)
IQR <- IQR(finalRef[[VARNAME]])
# subset data where points value is outside 1.5*IQR of Q1 and Q3
outliersRef <- subset(finalRef, finalRef[[VARNAME]]<(Q1 - 1.5*IQR) | finalRef[[VARNAME]]>(Q3 + 1.5*IQR))
newref <- subset(finalRef, !(finalRef[[VARNAME]]<(Q1 - 1.5*IQR) | finalRef[[VARNAME]]>(Q3 + 1.5*IQR)))
# outliersRef

# the new df for the final data with outliers that have been removeds
newfinaldata <- rbind(newTreat, newCont, newref)

# ---------------- AVERAGE DATA ----------------
# df - interested in daily means of the Treatment, Control, Reference
TreatContRef <- mean_plant_data(newfinaldata, ELEVATION, VARNAME)

# # TODO: these are not really needed, remove when it is confirmed they are not in use anywhere.
# # df - Treatment and Control
# TreatCont <- subset(TreatContRef, Data_leaftype != "Reference")
# # list - create two lists of data for the Welch's t-test
# Treat <- TreatContRef[TreatContRef$Data_leaftype == "Treatment",]$gm
# Cont <- TreatContRef[TreatContRef$Data_leaftype == "Control",]$gm
# Ref <- TreatContRef[TreatContRef$Data_leaftype == "Reference",]$gm

```

### Outlier Results

The number of Treatment data outliers removed: `r nrow(outliersTreat)`\
The number of Control data outliers removed: `r nrow(outliersCont)`\
The number of Reference data outliers removed: `r nrow(outliersRef)`
{{< pagebreak >}}  
# Data Exploration

Compare the original data vs wrangled data.

## *ALL* Daily Observations of `r VARNAME`

Plots of the original data are shown next to the wrangled data which have outliers removed.  

```{r graph_means}
#| echo: false
#| warning: false

# ------------------------------------------------

tdata <- finaldata %>% filter(Data_leaftype == "Treatment" & SysObs_time > 1668543540) %>% arrange(SysObs_date)
cdata <- finaldata %>% filter(Data_leaftype == "Control" & SysObs_time > 1668543540) %>% arrange(SysObs_date)
rdata <- finaldata %>% filter(Data_leaftype == "Reference" & SysObs_time > 1668543540) %>% arrange(SysObs_date)

t1 <- ggplot(tdata, aes(x = tdata[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(tdata, 
                c(mean = mean(tdata[[VARNAME]]), 
                  sd = sd(tdata[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Treatment - Original values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8)) # TODO change the scale of data values?

t2 <- ggplot(newTreat, aes(x = newTreat[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(newTreat, 
                c(mean = mean(newTreat[[VARNAME]]), 
                  sd = sd(newTreat[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Treatment - Wrangled values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8))

# ----------------------------

c1 <- ggplot(cdata, aes(x = cdata[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(cdata, 
                c(mean = mean(cdata[[VARNAME]]), 
                  sd = sd(cdata[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Control - Original values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8))

c2 <- ggplot(newCont, aes(x = newCont[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(newCont, 
                c(mean = mean(newCont[[VARNAME]]), 
                  sd = sd(newCont[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Control - Wrangled values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8))

# ----------------------------

r1 <- ggplot(rdata, aes(x = rdata[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(rdata, 
                c(mean = mean(rdata[[VARNAME]]), 
                  sd = sd(rdata[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Reference - Original values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8))

r2 <- ggplot(newref, aes(x = newref[[VARNAME]])) +
  stat_function(
    fun = dnorm,
    args = with(newref, 
                c(mean = mean(newref[[VARNAME]]), 
                  sd = sd(newref[[VARNAME]])))
  ) +
  scale_x_continuous(paste("Reference - Wrangled values of ", VARNAME, sep = '')) +
  scale_y_continuous(limits = c(0.0, 0.8))

t1 + t2
c1 + c2
r1 + r2
# ------------------------------------------------

```
{{< pagebreak >}}  
## AVERAGE Daily Observation of `r VARNAME`  

```{r}
#| echo: false
#| warning: false
 
TreatContRef$Data_leaftype <- factor(TreatContRef$Data_leaftype , levels=c("Treatment", "Control", "Reference"))
# all data, not transformed
all1 <-  ggplot() +
  # geom_boxplot(data = TreatContRef, aes(x = Data_leaftype, y = gm, color = Data_leaftype), outlier.color = "red", outlier.size = 3) +
  geom_boxplot(data = TreatContRef[TreatContRef$Data_leaftype == "Treatment",], 
               aes(x = Data_leaftype, y = gm, color = Data_leaftype), 
               outlier.color = "red", outlier.size = 3) +
  geom_boxplot(data = TreatContRef[TreatContRef$Data_leaftype == "Control",], 
               aes(x = Data_leaftype, y = gm, color = Data_leaftype), 
               outlier.color = "red", outlier.size = 3) +
  geom_boxplot(data = TreatContRef[TreatContRef$Data_leaftype == "Reference",], 
               aes(x = Data_leaftype, y = gm, color = Data_leaftype), 
               outlier.color = "red", outlier.size = 3) +  # scale_y_continuous(limits=c(0.0, 0.1)) +#, breaks=c(0, 2.5, 3.0, 3.5)) +
  ggtitle(paste("Elevation ", ELEVATION, "\nDaily Mean Observations on ", VARNAME, sep="")) +
  xlab("Leaf Type") +
  ylab(VARNAME)

all1

```
{{< pagebreak >}}  

## one-way ANOVA  
  H0: All group means are equal.  
  HA: At least one group mean is different from the rest.   
  
  p-val < $α$ reject H0  
  (https://www.statology.org/anova-assumptions/)  
  (https://www.statology.org/interpret-anova-results-in-r/)  

```{r anova_data}

#fit one-way ANOVA model
model <- aov(get(VARNAME) ~ Data_leaftype, data = newfinaldata)

summary(model)
```

{{< pagebreak >}}  
## Kruskal-Wallis test
(https://www.statology.org/kruskal-wallis-test-in-r/)  

Use instead of ANOVA

Kruskal-Wallis Test Assumptions
1. Ordinal or Continuous Response Variable – the response variable should be an ordinal or continuous variable. An example of an ordinal variable is a survey response question measured on a Likert Scale (e.g. a 5-point scale from “strongly disagree” to “strongly agree”) and an example of a continuous variable is weight (e.g. measured in pounds).

2. Independence – the observations in each group need to be independent of each other. Usually a randomized design will take care of this.

3. Distributions have similar shapes – the distributions in each group need to have a similar shape.

Test:  
H0: The median is equal across all groups  
H1: The median is not equal across all groups  
p-val < $α$ reject H0  

```{r}
#perform Kruskal-Wallis Test 
kruskal.test(get(VARNAME) ~ Data_leaftype, data = newfinaldata) 
```
{{< pagebreak >}}  

## Optional Post Hoc Test After ANOVA  
(https://www.statology.org/dunnetts-test-r/)  

If one of the groups in the study is considered the control group, then use Dunnett’s test as a post-hoc test.  

```{r}
# 
# boxplot(get(VARNAME) ~ Data_leaftype,
#         data = newfinaldata,
#         main = paste(VARNAME, " by Leaf", sep=''),
#         xlab = "Leaf",
#         ylab = VARNAME,
#         col = "steelblue",
#         border = "black")

#load DescTools library
library(DescTools)

#perform Dunnett's Test
DunnettTest(x=newfinaldata[[VARNAME]], g=newfinaldata$Data_leaftype)
```
{{< pagebreak >}}  

## Normality of Residuals
### Q-Q Plot  

### Shapiro-Wilk Test for normality of residuals   
H0: samples come from a normal distribution  
HA: samples do not come from a normal distribution    
p-val < $α$ reject H0  

```{r}
#create Q-Q plot to compare this dataset to a theoretical normal distribution 
qqnorm(model$residuals)

#add straight diagonal line to plot
qqline(model$residuals)

#Conduct Shapiro-Wilk Test for normality 
shapiro.test(newfinaldata[[VARNAME]])
```
{{< pagebreak >}}  

## Equal Variance  

### Bartlett's Test  
```{r}
#Create box plots that show distribution of weight loss for each group
bartlett.test(get(VARNAME) ~ Data_leaftype, data=newfinaldata)
```
```{r}
library(plyr)
 

df_summary <- newfinaldata %>% filter(Data_plant_id == 2) %>%
  filter(Data_leaftype == "Treatment" | 
           Data_leaftype == "Control" | 
           Data_leaftype == "Reference")

esummary <- ddply(df_summary, .(Filenames_filename, Data_leaftype, SysObs_date), summarise,
               mean = round(mean(GasEx_A), 2),
               sd = round(sd(GasEx_A), 2))
esummary <- na.omit(esummary)

ggplot(esummary, aes(x=SysObs_date, y=mean, color = Data_leaftype,group(Data_leaftype, SysObs_date))) +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), position = position_dodge(0.9), width = .2) +
  geom_line(size= 0.2) +
  geom_point(size = 2)

```
